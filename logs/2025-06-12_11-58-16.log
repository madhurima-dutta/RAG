[2025-06-12 11:58:16,317] [INFO] [app:main:98] - Streamlit app started.
[2025-06-12 11:58:16,318] [INFO] [app:user_input:79] - Received user question: explain me how the BERTweet works?
[2025-06-12 11:58:17,397] [INFO] [app:user_input:84] - Retrieved 4 relevant document chunks.
[2025-06-12 11:58:17,404] [INFO] [app:get_conversational_chain:66] - Creating conversational chain with Gemini...
[2025-06-12 11:58:17,408] [INFO] [app:get_conversational_chain:72] - Conversational chain created successfully.
[2025-06-12 11:58:23,007] [INFO] [app:user_input:89] - Generated response: BERTweet, a Roberta-based transformer model, is pre-trained on over 850 million English tweets.  It's designed to classify input text into one of three emotion classes: positive, negative, or neutral.  Its strength lies in its ability to understand short, colloquial, or emotionally expressive input, making it effective for sentiment analysis in informal language similar to social media.  The provided text mentions that BERTweet was fine-tuned using the SemEval 2017 corpus (around 40,000 tweets labeled for positive, neutral, and negative sentiment), as well as the Crowdflower Emotion Dataset (2016), GoEmotions, and MELD (Multimodal Emotional Dataset).  The fine-tuning process resulted in approximately 71% accuracy.
[2025-06-12 12:07:38,226] [INFO] [app:main:99] - Streamlit app started.
[2025-06-12 12:07:46,559] [INFO] [app:main:99] - Streamlit app started.
[2025-06-12 12:07:50,929] [INFO] [app:main:99] - Streamlit app started.
[2025-06-12 12:07:50,937] [INFO] [app:main:112] - 1 PDFs uploaded
[2025-06-12 12:07:50,941] [INFO] [app:get_pdf_text:33] - Extracting text from uploaded PDFs...
[2025-06-12 12:07:51,021] [INFO] [app:get_pdf_text:45] - Processed Saptarshi_Resume.pdf
[2025-06-12 12:07:51,021] [INFO] [app:get_text_chunks:51] - Splitting text into chunks...
[2025-06-12 12:07:51,021] [INFO] [app:get_text_chunks:55] - Generated 2 text chunks
[2025-06-12 12:07:51,021] [INFO] [app:get_vector_store:61] - Generating embeddings and saving FAISS index...
[2025-06-12 12:07:53,500] [INFO] [app:get_vector_store:66] - FAISS index saved
[2025-06-12 12:08:22,280] [INFO] [app:main:99] - Streamlit app started.
[2025-06-12 12:08:22,284] [INFO] [app:user_input:83] - User asked: give me details of the project?
[2025-06-12 12:08:23,295] [INFO] [app:user_input:88] - 2 matching documents found
[2025-06-12 12:08:23,295] [INFO] [app:get_conversational_chain:71] - Setting up conversational chain with Gemini...
[2025-06-12 12:08:23,302] [INFO] [app:get_conversational_chain:77] - Chain ready
[2025-06-12 12:08:27,904] [INFO] [app:user_input:91] - Response: The provided text details four projects:

**1. MoodTune - Emotion-Based Music Recommender (2025):** This project uses a Gemini LLM and transformer models from Hugging Face to analyze user text input for emotions and sentiment.  It combines this analysis to generate a final sentiment, which is then used to create personalized music recommendations via integration with OAuth and Spotify APIs.  The backend is built with FastAPI and uses a PostgreSQL database.  The project claims 93% accuracy.  It's hosted on GitHub.

**2. Bengali Caption Generator (2024):** This project involves a custom CNN-based image caption generator built using InceptionV3 and TensorFlow, achieving 85% semantic accuracy.  It includes textual consistency checks to align image context with language semantics.  The model is deployed on HuggingFace Spaces.

**3. Endangered Bird Sound Classification (2024):** This project uses a VGG16-inspired model with signal processing techniques (STFT and Mel-Spectrograms) to create a high-accuracy (98%) audio classifier for endangered bird sounds.  It's deployed as an interactive Streamlit app for real-time bird sound recognition.

**4.  A project with unspecified name (implied from research paper):**  A research paper titled  "Towards Classifying Bird Sounds Using a Deep Transfer Learning Model" was accepted at ICDMAI 2025.  Details about this project beyond the title are not provided.
[2025-06-12 12:19:22,915] [INFO] [app:main:96] - App started.
[2025-06-12 12:19:29,970] [INFO] [app:main:96] - App started.
[2025-06-12 12:19:33,618] [INFO] [app:main:96] - App started.
[2025-06-12 12:19:33,628] [INFO] [app:process_pdfs:40] - Starting PDF text extraction with metadata...
[2025-06-12 12:19:33,695] [INFO] [app:process_pdfs:59] - Processed PDF: Saptarshi_Resume.pdf
[2025-06-12 12:19:33,695] [INFO] [app:get_vector_store:30] - Generating embeddings with metadata...
[2025-06-12 12:19:36,005] [INFO] [app:get_vector_store:35] - FAISS vector store saved successfully.
[2025-06-12 12:19:40,186] [INFO] [app:main:96] - App started.
[2025-06-12 12:19:43,721] [INFO] [app:main:96] - App started.
[2025-06-12 12:19:46,559] [INFO] [app:main:96] - App started.
[2025-06-12 12:20:00,580] [INFO] [app:main:96] - App started.
[2025-06-12 12:20:02,917] [INFO] [app:main:96] - App started.
[2025-06-12 12:44:55,602] [INFO] [app:main:96] - App started.
[2025-06-12 12:44:56,993] [INFO] [app:main:96] - App started.
[2025-06-12 12:51:59,093] [INFO] [app:process_and_store:57] - Vector store created for Saptarshi_Resume.pdf with 2 chunks.
[2025-06-12 12:52:34,114] [INFO] [app:user_question_answer:85] - Response generated for Saptarshi_Resume.pdf: Saptarshi Dey is an aspiring data scientist with experience in building 5+ real-world ML/DL projects.  His skills encompass data analysis, deep learning, NLP, CV, and database management, using tools like Python, TensorFlow, PyTorch, PostgreSQL, FastAPI, and Streamlit.  His projects include an endangered bird sound classifier (98% accuracy, deployed on HuggingFace Spaces and Streamlit), a mood-based music recommender (93% accuracy using Gemini LLM), and a Bengali caption generator (85% accuracy, deployed on HuggingFace Spaces). He also has internship experience in data operations and data science, demonstrating skills in data cleaning, SQL optimization, model building (decision trees, facial recognition), and market segmentation.  His research paper, "Towards Classifying Bird Sounds Using a Deep Transfer Learning Model," was accepted at ICDMAI 2025.
[2025-06-12 12:55:59,669] [INFO] [app:process_and_store:41] - Replaced vector store for Saptarshi_Resume.pdf
[2025-06-12 12:56:02,212] [INFO] [app:process_and_store:57] - Vector store created for Saptarshi_Resume.pdf with 2 chunks.
[2025-06-12 12:56:15,388] [INFO] [app:process_and_store:57] - Vector store created for final year 8th sem project.pdf with 37 chunks.
[2025-06-12 12:56:30,664] [INFO] [app:user_question_answer:85] - Response generated for final year 8th sem project.pdf: This document describes a hybrid emotion-sentiment driven song recommendation system called MoodTune.  The system uses NLP, specifically DistilRoBERTa for emotion detection (9 Ekman emotions) and BERTweet for sentiment analysis (positive, neutral, negative), to process user input text.  A weighted scoring system combines emotion and sentiment to determine a final mood, which is then used to generate a music query for the Gemini LLM.  The Spotify API retrieves song and playlist recommendations based on this query.  The system was tested with various real-world emotional inputs, and the results (including a confusion matrix for BERTweet) are presented.  The architecture includes a React.js frontend, a FastAPI backend, and a PostgreSQL database.
